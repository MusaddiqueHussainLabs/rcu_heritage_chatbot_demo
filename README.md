# ğŸ“œ RCU Heritage AI Chatbot â€“ Image & Knowledge-Based Retrieval System

An AI-powered multimodal heritage assistant built for **Royal Commission for AlUla (RCU)** that enables:

* ğŸ“– Knowledge-based search over heritage documents (PDF)
* ğŸ–¼ Image-based object recognition & explanation
* ğŸ¤– Agentic AI orchestration using tools
* ğŸ” Vector search with ChromaDB
* ğŸ’¬ Integration-ready with Microsoft 365 Agents

---

# ğŸ“Œ Overview

This project demonstrates an **Agentic AI-powered Heritage Chatbot** capable of:

1. Retrieving information from RCU heritage documents.
2. Searching similar artifacts based on uploaded images.
3. Explaining historical context using LLM + RAG.
4. Running as a Microsoft 365 Agents or FastAPI-based backend service.
5. Integrating with Microsoft Agents SDK / Omnichannel.

The system uses:

* **LangChain**
* **ChromaDB**
* **Groq LLM**
* **Microsoft 365 Agents**
* **Agent + Tools architecture**

---

Perfect â€” add the following section in your `README.md` under a new heading like:

---

## ğŸ“š Data Source Attribution

The PDF document used in this repository:

**â€œAlUla Collections â€“ 100 Objectsâ€**

has been sourced from the official Royal Commission for AlUla (RCU) Open Data Library:

ğŸ”— [https://www.rcu.gov.sa/en/open-data-library/alula-collections-100-objects](https://www.rcu.gov.sa/en/open-data-library/alula-collections-100-objects)

This material is publicly available through RCUâ€™s Open Data platform and is used in this repository strictly for demonstration and research purposes to showcase AI-powered heritage knowledge retrieval and image-based search capabilities.

All intellectual property rights and ownership of the original content remain with the Royal Commission for AlUla (RCU).

---


# ğŸ› Architecture Overview

## 1ï¸âƒ£ High-Level Flow

```
User â†’ Bot Channel (LiveChat) â†’              Agent
                                               â†“
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚                             â”‚
                         PDF Knowledge RAG              Image Search Tool
                                â”‚                             â”‚
                          ChromaDB Vector Store        Embedding + Retrieval
                                â”‚                             â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â†“
                                       Structured Response
                                               â†“
                                           User Reply
```

---

# ğŸŒ Open Sourceâ€“First Architecture

This project is intentionally designed using **open-source technologies and standards**, ensuring:

* âœ… No vendor lock-in
* âœ… Full transparency of components
* âœ… Extensibility and customization
* âœ… Enterprise portability (on-prem / cloud / hybrid)
* âœ… Cost optimization

All core architectural layers leverage OSS frameworks and libraries.

---

# ğŸ§© Open Source Technology Stack

Below is a breakdown of the open-source components used in this solution:

| Layer            | Technology                                  | Open Source Status |
| ---------------- | ------------------------------------------- | ------------------ |
| API Framework    | **FastAPI**                                 | Open Source (MIT)  |
| AI Orchestration | **LangChain**                               | Open Source        |
| Vector Database  | **ChromaDB**                                | Open Source        |
| Data Processing  | **Python**                                  | Open Source        |
| Embeddings       | **hugging face** embedding models           | Open               |
| Notebook         | **Jupyter Notebook**                        | Open Source        |
| Web Server       | **Uvicorn**                                 | Open Source        |
| Dependency Mgmt  | **pip / venv**                              | Open Source        |

> The architecture remains fully portable and can run in any standard Python environment without proprietary infrastructure requirements.

---

# ğŸ“‚ Repository Structure

```
rcu_heritage_chatbot_demo/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents.py              # Agent definitions & orchestration logic
â”‚   â”œâ”€â”€ app.py                 # Bot message handling logic
â”‚   â”œâ”€â”€ llm_model.py           # Groq LLM configuration
â”‚   â”œâ”€â”€ response_schemas.py    # Pydantic response schemas
â”‚   â”œâ”€â”€ tools.py               # Image search & RAG tools
â”‚   â”œâ”€â”€ main.py                # app entry
â”‚   â”œâ”€â”€ start_server.py        # Local server bootstrap
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ alula-collections-100-objects.pdf
â”‚   â”œâ”€â”€ chroma_langchain_db/   # Vector DB persistence
â”‚   â”œâ”€â”€ uploaded_images/       # Uploaded images
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ images/            # pdf containes images    
â”‚       â”œâ”€â”€ langchain_docs.json
â”‚       â””â”€â”€ objects.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_ingestion_to_chromadb.ipynb  # PDF ingestion workflow
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

# ğŸ§  Core Components Explained

---

## 1ï¸âƒ£ LLM Layer â€“ `llm_model.py`

Configures Groq LLM used by the agent.

Responsible for:

* Response generation
* Tool calling decisions
* Structured output formatting

---

## 2ï¸âƒ£ Tools â€“ `tools.py`

Implements:

### ğŸ” Knowledge RAG Tool

* Uses ChromaDB
* Retrieves relevant document chunks
* Returns contextual explanation

### ğŸ–¼ Image Search Tool

* Accepts local image path
* Generates embeddings
* Retrieves similar artifacts
* Produces explanation

---

## 3ï¸âƒ£ Agent â€“ `agents.py`

Defines:

* Tool-enabled AI agent
* Structured JSON output
* Tool routing logic
* Controlled response schema

---

## 4ï¸âƒ£ Bot Handling â€“ `app.py`

Handles:

* Incoming messages
* Image uploads
* File download
* Agent invocation
* Response sending

---

## 5ï¸âƒ£ Vector Database â€“ ChromaDB

Location:

```
data/chroma_langchain_db/
```

Stores:

* Embedded PDF chunks
* Artifact embeddings
* Metadata

Persistent across sessions.

---

# ğŸš€ How to Run (Step-by-Step)

---

# âœ… Step 1: Clone Repository

```bash
git clone https://github.com/MusaddiqueHussainLabs/rcu_heritage_chatbot_demo.git
cd rcu_heritage_chatbot_demo
```

---

# âœ… Step 2: Create Virtual Environment

### Windows

```bash
python -m venv .venv
.venv\Scripts\activate
```

### Mac/Linux

```bash
python3 -m venv .venv
source .venv/bin/activate
```

---

# âœ… Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

---

# âœ… Step 4: Set Environment Variables

Create `.env` file:

```
GROQ_API_KEY=your_groq_api_key
```

If using Microsoft Bot Framework:

```
MICROSOFT_APP_ID=your_app_id
MICROSOFT_APP_PASSWORD=your_password
```

---

# âœ… Step 5: Start Server

```bash
python app/start_server.py
```

Or:

```bash
uvicorn app.main:app --reload --port 8000
```

Server runs at:

```
http://localhost:8000
```

---

# ğŸ–¼ Image Upload Workflow

When user uploads image:

1. Bot receives attachment
2. Image saved to:

```
data/uploaded_images/
```

3. Agent invoked with:

```
search_by_image_and_explain(image_path=...)
```

4. Tool retrieves similar artifacts
5. LLM generates explanation
6. Response sent to user

---

# ğŸ“– How to Ingest New PDF Data

Open notebook:

```
notebooks/data_ingestion_to_chromadb.ipynb
```

Steps:

1. Load PDF
2. Chunk text
3. Generate embeddings
4. Store in ChromaDB

After ingestion:

* Restart server
* New data searchable immediately

---

# ğŸ§© How to Utilize This Repo (RCU Usage Guide)

This repository can be used in 3 ways:

---

## 1ï¸âƒ£ Reference Implementation

RCU can:

* Review architecture
* Extend tools
* Integrate with enterprise channels
* Deploy to Azure

---

## 2ï¸âƒ£ Production Deployment

Recommended Production Setup:

* Azure App Service
* Azure Container Apps
* Azure OpenAI (optional replacement for Groq)
* Azure Cosmos DB (optional vector DB alternative)

---

## 3ï¸âƒ£ Extension Use Cases

Can be extended to:

* Multi-language Arabic support
* Audio-based artifact recognition
* Museum kiosk integration
* Visitor mobile app integration
* Guided tour AI assistant

---

# ğŸ” Security Considerations

* Never expose raw tool traces
* Limit response size
* Sanitize LLM output
* Secure API keys in Key Vault
* Use HTTPS in production

---

# âš™ Performance Optimization

* Limit response length (<4000 chars)
* Use persistent ChromaDB
* Cache embeddings
* Send immediate acknowledgement to avoid channel timeout

---

# ğŸ“Š Technology Stack

| Layer           | Technology           |
| --------------- | -------------------- |
| Agent Framework | LangChain            |
| LLM             | Groq                 |
| Vector DB       | ChromaDB             |
| Bot Integration | Microsoft Agents SDK |
| Storage         | Local filesystem     |
| Notebook        | Jupyter              |

---

# ğŸ— Production Deployment Recommendation for RCU

For enterprise readiness:

1. Dockerize application
2. Deploy to Azure Kubernetes Service
3. Use Azure Key Vault
4. Replace local storage with Azure Blob
5. Use Azure Monitor
6. Add centralized logging

---

# ğŸ¯ Key Capabilities Delivered

âœ” Multimodal Search
âœ” Agentic Tool Routing
âœ” Vector-Based Retrieval
âœ” Structured Response Schema
âœ” Enterprise-Ready Architecture
âœ” LiveChat Integration

---

# ğŸ”® Future Roadmap

* Arabic LLM support
* Multi-agent supervisor routing
* Fine-tuned heritage domain model
* On-prem deployment option
* Vision transformer integration

---

# ğŸ“ Maintainer

**Musaddique Hussain Labs**
AI Architect & Agentic AI Specialist

GitHub:
[https://github.com/MusaddiqueHussainLabs](https://github.com/MusaddiqueHussainLabs)

---

# ğŸ“„ License

This project is licensed under the MIT License.

---

# ğŸ Final Notes for RCU

This repository demonstrates a scalable foundation for:

> "AI-Powered Digital Heritage Intelligence Platform"

It can serve as:

* A reference prototype
* A production-ready base
* A foundation for enterprise AI transformation